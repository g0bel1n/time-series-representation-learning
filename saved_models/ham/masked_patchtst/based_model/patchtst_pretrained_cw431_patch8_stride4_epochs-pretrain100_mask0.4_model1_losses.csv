train_loss,valid_loss
1.048295,1.013298
1.043285,1.030045
1.102794,1.023679
1.073401,0.999177
0.998742,1.018165
0.993141,0.971269
1.004010,1.025099
0.986868,0.908417
0.981336,0.963527
1.039552,0.981627
1.002684,0.930598
0.924978,0.956425
0.976786,0.935472
0.975440,0.955535
0.872915,0.759127
0.766525,0.659061
0.642561,0.565769
0.538635,0.444143
0.473944,0.411911
0.424439,0.479745
0.377060,0.388144
0.364941,0.324531
0.333061,0.320727
0.296011,0.276899
0.290984,0.253017
0.272545,0.251771
0.258761,0.272895
0.257920,0.236479
0.247943,0.231785
0.239264,0.250424
0.227984,0.243081
0.231905,0.245897
0.231703,0.244328
0.222276,0.227989
0.222535,0.231010
0.218298,0.241592
0.221948,0.211071
0.228833,0.236709
0.218301,0.220598
0.212329,0.219340
0.207770,0.244004
0.222929,0.227250
0.204731,0.227722
0.223961,0.224343
0.224227,0.229245
0.210834,0.222905
0.208805,0.210272
0.217027,0.213311
0.202893,0.213130
0.202182,0.218666
0.196232,0.218255
0.206439,0.213841
0.201496,0.206206
0.194223,0.208411
0.194738,0.216014
0.196900,0.219166
0.197181,0.218829
0.194296,0.215178
0.197209,0.220622
0.197154,0.215295
0.192928,0.226145
0.195825,0.205499
0.200049,0.205640
0.197201,0.207061
0.188393,0.221172
0.198974,0.212653
0.194979,0.207323
0.192470,0.204746
0.192412,0.210602
0.194081,0.198585
0.184743,0.216123
0.190079,0.193759
0.187181,0.200437
0.186713,0.206277
0.186532,0.205954
0.182047,0.210092
0.185202,0.203478
0.185118,0.206878
0.182869,0.204985
0.197614,0.214459
0.189270,0.212834
0.186914,0.201324
0.179179,0.209945
0.179756,0.201121
0.187065,0.195928
0.184265,0.201324
0.181162,0.197561
0.183685,0.210765
0.186056,0.210281
0.179971,0.212878
0.184440,0.218479
0.189514,0.205225
0.186591,0.208286
0.184840,0.206710
0.179857,0.210773
0.190481,0.207059
0.176417,0.196921
0.183845,0.202568
0.184275,0.212640
0.187691,0.203299
